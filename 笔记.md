### 
1. start.S中ttbr0_el1和ttbr1_el1是一样的，可能需要修改
2. 在 src/aarch64/mmu.h 定义了 K2P 和 P2K 两个宏，用于内核虚拟地址和物理地址的相互转换

### 
1. create_Proc
gobally的pid
开一个栈
初始化好
并选择父进程
2. start_proc
里面有一个函数指针
runnable

3. pick_next
来选一个进程去执行
4. wait
等待子进程去执行，如有，就变成sleeping
子进程运行退出会唤醒父进程
exit主动退出，free一些参数
sched函数是把自己变成什么状态的意思

5. wait_sem

trap.S
里面的trap难写，助教直接给

6. 信号量
资源可用的数量
wait_sem时，会把value减一，表示占用资源，如果资源不足，则sleeping，进入sleeping_list
post_sem时，资源可用，又唤醒

可以先把核的数量变成1，先跑通代码


我写的调度器有问题，只有cpu0会产生22个进程后卡死，其他cpu什么都不干：
Available memory size is 1060540416 bytes.
cpuid: 0, start pid: 1
CPU 0: hello
CPU 1: hello
CPU 2: hello
this cpu is 1, process's pid is -2, state is 2
CPU 3: hello
this cpu is 0, process's pid is -1, state is 2
Hello world! (Core 1)
proc_test
this cpu is 2, process's pid is -3, state is 2
this cpu is 3, process's pid is -4, state is 2
cpuid: 1, start pid: 2
this cpu is 0, process's pid is -1, state is 2
proc_test_1
proc.c:224, cpuid is 1
this cpu is 1, process's pid is 1, state is 2
cpuid: 0, start pid: 3
cpuid: 0, start pid: 4
cpuid: 0, start pid: 5
cpuid: 0, start pid: 6
cpuid: 0, start pid: 7
cpuid: 0, start pid: 8
cpuid: 0, start pid: 9
cpuid: 0, start pid: 10
cpuid: 0, start pid: 11
cpuid: 0, start pid: 12
proc.c:224, cpuid is 0
this cpu is 0, process's pid is 2, state is 2
cpuid: 0, start pid: 13
cpuid: 0, start pid: 14
cpuid: 0, start pid: 15
cpuid: 0, start pid: 16
cpuid: 0, start pid: 17
cpuid: 0, start pid: 18
cpuid: 0, start pid: 19
cpuid: 0, start pid: 20
cpuid: 0, start pid: 21
cpuid: 0, start pid: 22
proc.c:224, cpuid is 0
this cpu is 0, process's pid is 3, state is 2
proc.c:224, p->state is 2
this cpu is 0, process's pid is 13, state is 2
CPU 2: living
CPU 3: living
CPU 1: living
this cpu is 2, process's pid is -3, state is 2
this cpu is 3, process's pid is -4, state is 2
this cpu is 1, process's pid is -2, state is 2
this cpu is 2, process's pid is -3, state is 2
this cpu is 3, process's pid is -4, state is 2
this cpu is 1, process's pid is -2, state is 2
CPU 3: living
this cpu is 3, process's pid is -4, state is 2
CPU 2: living
CPU 1: living
this cpu is 3, process's pid is -4, state is 2
this cpu is 1, process's pid is -2, state is 2
this cpu is 2, process's pid is -3, state is 2
this cpu is 1, process's pid is -2, state is 2
this cpu is 2, process's pid is -3, state is 2
CPU 1: living
CPU 3: living
this cpu is 1, process's pid is -2, state is 2
CPU 2: living
this cpu is 3, process's pid is -4, state is 2
this cpu is 2, process's pid is -3, state is 2
this cpu is 1, process's pid is -2, state is 2
this cpu is 3, process's pid is -4, state is 2
this cpu is 2, process's pid is -3, state is 2
QEMU: Terminated
[100%] Built target qemu
#sched.c
// sched.c

#include <kernel/sched.h>
#include <kernel/proc.h>
#include <kernel/mem.h>
#include <kernel/printk.h>
#include <aarch64/intrinsic.h>
#include <kernel/cpu.h>
#include <common/rbtree.h>
#include <kernel/debug.h>
extern bool panic_flag;

extern void swtch(KernelContext *new_ctx, KernelContext **old_ctx);

// --- 定义全局调度资源 ---
struct rb_root_ global_run_queue;
SpinLock global_sched_lock;
u64 global_min_vruntime = 0;
// --------------------
extern Proc idle_procs[];
void create_idle_proc(){
for (int i=0;i<NCPU;i++){
cpus[i].sched.idle=&idle_procs[i];
Proc *p=&idle_procs[i];
p->state=RUNNING;
p->idle=TRUE;
p->pid=-1-i;
// p->kstack=(void *)idle_stacks[i];
// p->kstack=kalloc_page();
p->parent=NULL;
// init_list_node(&p->children);
// init_list_node(&p->ptnode);
// schinfo不会用到，不必初始化
//当前位于栈底
// void *sp=(void *)p->kstack+PAGE_SIZE;
// p->ucontext=NULL;
// p->kcontext=(KernelContext *)(sp-sizeof(KernelContext));
// memset(p->kcontext,0,sizeof(KernelContext));
// p->kcontext->lr=(u64)idle_entry;
cpus[i].sched.current_proc = p;
cpus[i].sched.idle=p;
}
}
void update_vruntime(Proc p){
if (p==NULL||p->idle==TRUE){
return;
}
u64 now=get_timestamp();
u64 delta_exec=now-p->schinfo.start_exec_time;
// 应该不会为负数
int weight=WEIGHT(p->schinfo.nice);
u64 delta_vruntime=(delta_execWEIGHT(0))/weight;
p->schinfo.vruntime+=delta_vruntime;
}

bool compare_runtime(rb_node lnode, rb_node rnode){
// 先找到这个红黑树节点所在的进程
Proc *p1=container_of(lnode,Proc,schinfo.node);
Proc *p2=container_of(rnode,Proc,schinfo.node);
return p1->schinfo.vruntime<p2->schinfo.vruntime;
}

void init_sched()
{
// TODO: initialize the scheduler
// 1. initialize the resources (e.g. locks, semaphores)
// --- 初始化全局资源 ---
create_idle_proc();
init_spinlock(&global_sched_lock);
global_run_queue.rb_node = NULL;
// -------------------


// 2. initialize the scheduler info of each CPU
for (int i=0;i<NCPU;i++){
    struct sched *temp=&cpus[i].sched;
    // init_spinlock(&temp->lock); // 已移至全局
    // temp->run_queue.rb_node=NULL; // 已移至全局
    temp->task_count=0; // 注意：task_count的含义可能需要重新审视
    // temp->current_proc=NULL;
    // temp->idle=NULL; a
}
}

Proc *thisproc()
{
// TODO: return the current process
// 可以根据当前的CPU是哪个来找到这个进程是哪个
int id=cpuid();
return cpus[id].sched.current_proc;
}

void init_schinfo(struct schinfo *p)
{
// TODO: initialize your customized schinfo for every newly-created process
p->vruntime=0;
p->nice=0;
// 后续还会更新并覆盖的，这里可以直接设置为0
p->start_exec_time=0;
}

void acquire_sched_lock()
{
// TODO: acquire the sched_lock if need
acquire_spinlock(&global_sched_lock);
}

void release_sched_lock()
{
// TODO: release the sched_lock if need
release_spinlock(&global_sched_lock);
}

bool is_zombie(Proc *p)
{
bool r;
acquire_sched_lock();
r = p->state == ZOMBIE;
release_sched_lock();
return r;
}

bool activate_proc(Proc *p)
{
// TODO:
acquire_sched_lock();
// if the proc->state is RUNNING/RUNNABLE, do nothing
if (p->state==RUNNING||p->state==RUNNABLE){
release_sched_lock();
return false;
}
// if the proc->state if SLEEPING/UNUSED, set the process state to RUNNABLE and add it to the sched queue
else if (p->state==SLEEPING||p->state==UNUSED){
p->state=RUNNABLE;
if (p->schinfo.vruntime < global_min_vruntime) {
p->schinfo.vruntime = global_min_vruntime;
}
_rb_insert(&p->schinfo.node, &global_run_queue, compare_runtime);
// cpus[cpuid()].sched.task_count++; // 这个计数器现在是全局的了
// -------------------
}
// else: panic
else {
PANIC();
}
release_sched_lock();
return true;
}

// 用来把当前运行的函数切换出去，可能切换为RUNNABLE\SLEEPING\ZOMBIE
static void update_this_state(enum procstate new_state)
{
// TODO: if you use template sched function, you should implement this routinue
// update the state of current process to new_state, and modify the sched queue if necessary
Proc *this=thisproc();
if (this->idle){
return;
}
update_vruntime(this);
this->state=new_state;
if (new_state==RUNNABLE){
_rb_insert(&this->schinfo.node, &global_run_queue, compare_runtime);
// cpus[cpuid()].sched.task_count++;
// -------------------
}else if(new_state==SLEEPING||new_state==ZOMBIE){
// //不需要减少任务计数


}
}

// static Proc *pick_next()
// {
// // TODO: if using template sched function, you should implement this routinue
// // choose the next process to run, and return idle if no runnable process
// if (panic_flag) return cpus[cpuid()].sched.idle;

// // --- 使用全局红黑树 ---
// rb_node next_node=_rb_first(&global_run_queue);
// // -------------------

// if (next_node){
// _rb_erase(next_node, &global_run_queue);
// // cpus[cpuid()].sched.task_count--;
// Proc *next_proc=container_of(next_node,Proc,schinfo.node);
// rb_node *new_first = _rb_first(&global_run_queue);
// if (new_first) {
// Proc *p = container_of(new_first, Proc, schinfo.node);
// global_min_vruntime = p->schinfo.vruntime;
// }

// next_proc->schinfo.start_exec_time=get_timestamp();

// return next_proc;
// }else{
// return cpus[cpuid()].sched.idle;
// }
// }
static Proc *pick_next()
{
// TODO: if using template sched function, you should implement this routinue
// choose the next process to run, and return idle if no runnable process
if (panic_flag) return cpus[cpuid()].sched.idle;

// --- 使用全局红黑树 ---
// rb_node 已经被 typedef 为 struct rb_node_ *
rb_node next_node=_rb_first(&global_run_queue);
// -------------------

if (next_node){
    _rb_erase(next_node, &global_run_queue);
    
    // 在取出 vruntime 最小的进程后，更新全局的 min_vruntime
    // 使其指向新的 vruntime 最小的进程。
    rb_node new_first = _rb_first(&global_run_queue);
    if (new_first) {
        Proc *p = container_of(new_first, Proc, schinfo.node);
        global_min_vruntime = p->schinfo.vruntime;
    }

    // cpus[cpuid()].sched.task_count--;
    Proc *next_proc=container_of(next_node,Proc,schinfo.node);
 
    next_proc->schinfo.start_exec_time=get_timestamp();
    
    return next_proc;
}else{
    return cpus[cpuid()].sched.idle;
}
}

// 设置当前CPU运行的进程
static void update_this_proc(Proc *p)
{
// TODO: you should implement this routinue
// update thisproc to the choosen process
// reset_clock(1000);
cpus[cpuid()].sched.current_proc=p;
}

// A simple scheduler.
// You are allowed to replace it with whatever you like.
// call with sched_lock
void sched(enum procstate new_state)
{
auto this = thisproc();
#ifdef debug_sched
// if (this->state != RUNNING)
printk("this cpu is %lld, process's pid is %d, state is %d\n",cpuid(), this->pid, this->state);
#endif
ASSERT(this->state == RUNNING);
//! 给进程传入新的目标状态
update_this_state(new_state);
auto next = pick_next();
update_this_proc(next);
if (next->state!=RUNNABLE && !next->idle){
printk("This proc is: %d, it is %d\n",this->pid,this->state);
printk("Next proc is: %d, it is %d\n",next->pid,next->state);
}
ASSERT(next->state == RUNNABLE||next->idle);
next->state = RUNNING;
if (next != this) {
swtch(next->kcontext, &this->kcontext);
}
release_sched_lock();
}

u64 proc_entry(void (*entry)(u64), u64 arg)
{
release_sched_lock();
set_return_addr(entry);
return arg;
}
#proc.c
#include <kernel/proc.h>
#include <kernel/mem.h>
#include <kernel/sched.h>
#include <aarch64/mmu.h>
#include <common/list.h>
#include <common/string.h>
#include <kernel/printk.h>
#include <kernel/debug.h>
#include <kernel/core.h>
#include <kernel/cpu.h>
#ifndef NCPU
#define NCPU 4
#endif
Proc root_proc;

void kernel_entry();
u64 proc_entry();

SpinLock global_process_lock;
int prio_to_weight[40]={
/* -20 / 88761, 71755, 56483, 46273, 36291,
/ -15 / 29154, 23254, 18705, 14949, 11916,
/ -10 / 9548, 7620, 6100, 4904, 3906,
/ -5 / 3121, 2501, 1991, 1586, 1277,
/ 0 / 1024, 820, 655, 526, 423,
/ 5 / 335, 272, 215, 172, 137,
/ 10 / 110, 87, 70, 56, 45,
/ 15 */ 36, 29, 23, 18, 15,
};
static int allocated_pid;

void init_pid_allocator(){
allocated_pid=0;
}

int pid_allocator(){
++allocated_pid;
return allocated_pid;
}

Proc idle_procs[NCPU];
// static u8 idle_stacks[NCPU][PAGE_SIZE] attribute((aligned(PAGE_SIZE)));

// typedef struct Proc {
// bool killed;
// bool idle;√
// int pid;√
// int exitcode;
// enum procstate state;√
// Semaphore childexit;
// ListNode children;
// ListNode ptnode;
// struct Proc *parent;√
// struct schinfo schinfo;
// void *kstack;√
// UserContext *ucontext;√
// KernelContext *kcontext;√
// } Proc;

// init_kproc initializes the kernel process
// NOTE: should call after kinit
void init_kproc()
{
// TODO:
// 1. init global resources (e.g. locks, semaphores)
init_spinlock(&global_process_lock);
// pid计数器
init_pid_allocator();


// 2. init the root_proc (finished)

init_proc(&root_proc);
root_proc.parent = &root_proc;
start_proc(&root_proc, kernel_entry, 123456);
}

void init_proc(Proc *p)
{
// TODO:
// setup the Proc with kstack and pid allocated
// NOTE: be careful of concurrency


memset(p,0,sizeof(Proc));

acquire_spinlock(&global_process_lock);

init_sem(&p->childexit, 1);
init_list_node(&p->children);
init_list_node(&p->ptnode);
p->idle = FALSE;
p->exitcode=0;
p->killed=FALSE;
p->pid=pid_allocator();
p->state=UNUSED;
p->kstack=kalloc_page();
init_schinfo(&p->schinfo);
if (p->kstack==NULL){
    release_spinlock(&global_process_lock);
    PANIC();
}
memset(p->kstack,0,PAGE_SIZE);

// 这里会覆盖掉的，没必要写
p->kcontext=(KernelContext *)((u64)p->kstack+PAGE_SIZE-16-sizeof(KernelContext));
p->ucontext=(UserContext *)((u64)p->kstack+PAGE_SIZE-16-sizeof(KernelContext)-sizeof(UserContext));

release_spinlock(&global_process_lock);
}

Proc *create_proc()
{
Proc *p = kalloc(sizeof(Proc));
if (p==NULL){
PANIC();
}
init_proc(p);
return p;
}

void set_parent_to_this(Proc *proc)
{
// TODO: set the parent of proc to thisproc
// NOTE: maybe you need to lock the process tree
// NOTE: it's ensured that the old proc->parent = NULL

acquire_spinlock(&global_process_lock);
Proc *parent=thisproc();
proc->parent=parent;
// #ifdef debug_page_fault
// printk("proc.c:144: proc's ptnode is %llx\n", (u64)&proc->ptnode);
// #endif
_insert_into_list(&parent->children,&proc->ptnode);
release_spinlock(&global_process_lock);
}

int start_proc(Proc *p, void (*entry)(u64), u64 arg)
{
// TODO:
// 1. set the parent to root_proc if NULL
if (p->parent==NULL){
acquire_spinlock(&global_process_lock);
p->parent=&root_proc;

    _insert_into_list(&root_proc.children, &p->ptnode);

    release_spinlock(&global_process_lock);
}
// 2. setup the kcontext to make the proc start with proc_entry(entry, arg)
// void *sp=(void *)p->kstack+PAGE_SIZE;
// sp-=sizeof(KernelContext);
// p->kcontext=(KernelContext *)sp;
// memset(p->kcontext,0,sizeof(KernelContext));
p->kcontext->lr=(u64)proc_entry;
p->kcontext->x0=(u64)entry;
p->kcontext->x1=(u64)arg;
// 3. activate the proc and return its pid
p->state=UNUSED;
int id =p->pid;
activate_proc(p);//activate函数内部有锁
// NOTE: be careful of concurrency
printk("cpuid: %lld, start pid: %d\n",cpuid(),p->pid);
return id;
}

int wait(int *exitcode)
{
// TODO:
Proc *parent=thisproc();
// 1. return -1 if no children
// acquire_spinlock(&global_process_lock);
// if (_empty_list(&parent->children)){
// release_spinlock(&global_process_lock);
// return -1;
// }
acquire_spinlock(&global_process_lock);
while (1){

    // if (_empty_list(&parent->children)){
    //     release_spinlock(&global_process_lock);
    //     return -1;
    // }
// 2. wait for childexit
// 3. if any child exits, clean it up and return its pid and exitcode
    Proc *zombie_child=NULL;
    bool has_children = !_empty_list(&parent->children);
    if (has_children) {
        _for_in_list(node, &parent->children) {
            Proc *p = container_of(node, Proc, ptnode);
            if (p->state == ZOMBIE) {
                zombie_child = p;
                break;
            }
        }
    }
    if (zombie_child){
        if (exitcode!=NULL){
            *exitcode=zombie_child->exitcode;

        }
        int child_pid=zombie_child->pid;
        if (zombie_child->kstack){
            kfree_page(zombie_child->kstack);
        }
        _detach_from_list(&zombie_child->ptnode);
        // zombie_child->state=UNUSED;
        // zombie_child->pid=0;
        kfree(zombie_child);
        release_spinlock(&global_process_lock);
        return child_pid;
    }
    if (!has_children){
        release_spinlock(&global_process_lock);
    }
// NOTE: be careful of concurrency
    release_spinlock(&global_process_lock);
    wait_sem(&parent->childexit);

    acquire_spinlock(&global_process_lock);
}
}

NO_RETURN void exit(int code)
{
// TODO:
// 1. set the exitcode

acquire_spinlock(&global_process_lock);
Proc *p=thisproc();
// p->state=ZOMBIE; //会导致sched.c:163发生PANIC
#ifdef debug_sched //{ UNUSED, RUNNABLE, RUNNING, SLEEPING, ZOMBIE };
printk("proc.c:224, p->state is %d\n",p->state);
#endif
p->exitcode=code;
// 2. clean up the resources


// 3. transfer children to the root_proc, and notify the root_proc if there is zombie
_for_in_list(node,&p->children){
    Proc *child=container_of(node,Proc,ptnode);
    child->parent=&root_proc;
}
// #ifdef debug_page_fault
// printk("proc's ptnode is %llx, proc's children is %llx\n", (u64)&p->ptnode,(u64)&p->children);
// #endif
if (!_empty_list(&p->children)){
ListNode *temp=_detach_from_list(&p->children);
_merge_list(&root_proc.children, temp);
}
init_list_node(&p->children);
if (p->parent){
post_sem(&p->parent->childexit);
}

// 4. sched(ZOMBIE)
acquire_sched_lock();
sched(ZOMBIE);
// NOTE: be careful of concurrency
release_spinlock(&global_process_lock);
// kfree(p);
PANIC(); // prevent the warning of 'no_return function returns'
}
#proc_test.c
#include <kernel/sched.h>
#include <common/sem.h>
#include <test/test.h>
#include <kernel/mem.h>
#include <kernel/printk.h>

void set_parent_to_this(Proc *proc);

static Semaphore s1, s2, s3, s4, s5, s6;

// proc_test_1
// 0: wait 10-19
// 1: give living 20-29 to root_proc
// 2: give dead 30-39 to root_proc
// 34567: 40-89 odd P(s2) even V(s2)
// 8: 90-99 V(s3) P(s4) get_all
// 9: 100-109 P(s5) V(s6) post

static void proc_test_1b(u64 a)
{
switch (a / 10 - 1) {
case 0:
break;
case 1:
yield();
yield();
yield();
break;
case 2:
post_sem(&s1);
break;
case 3:
case 4:
case 5:
case 6:
case 7:
if (a & 1)
post_sem(&s2);
else
wait_sem(&s2);
break;
case 8:
wait_sem(&s3);
post_sem(&s4);
break;
case 9:
post_sem(&s5);
wait_sem(&s6);
break;
}
exit(a);
}

static void proc_test_1a(u64 a)
{
for (int i = 0; i < 10; i++) {
auto p = create_proc();
set_parent_to_this(p);
start_proc(p, proc_test_1b, a * 10 + i + 10);
}
switch (a) {
case 0: {
int t = 0, x;
for (int i = 0; i < 10; i++) {
wait(&x);
t |= 1 << (x - 10);
}
ASSERT(t == 1023);
ASSERT(wait(&x) == -1);
} break;
case 1:
break;
case 2: {
for (int i = 0; i < 10; i++)
ASSERT(wait_sem(&s1));
ASSERT(!get_sem(&s1));
} break;
case 3:
case 4:
case 5:
case 6:
case 7: {
int x;
for (int i = 0; i < 10; i++)
wait(&x);
ASSERT(wait(&x) == -1);
} break;
case 8: {
int x;
for (int i = 0; i < 10; i++)
post_sem(&s3);
for (int i = 0; i < 10; i++)
wait(&x);
ASSERT(wait(&x) == -1);
ASSERT(s3.val == 0);
ASSERT(get_all_sem(&s4) == 10);
} break;
case 9: {
int x;
for (int i = 0; i < 10; i++)
wait_sem(&s5);
for (int i = 0; i < 10; i++)
post_sem(&s6);
for (int i = 0; i < 10; i++)
wait(&x);
ASSERT(wait(&x) == -1);
ASSERT(s5.val == 0);
ASSERT(s6.val == 0);
} break;
}
exit(a);
}

static void proc_test_1()
{
printk("proc_test_1\n");
init_sem(&s1, 0);
init_sem(&s2, 0);
init_sem(&s3, 0);
init_sem(&s4, 0);
init_sem(&s5, 0);
init_sem(&s6, 0);
int pid[10];
for (int i = 0; i < 10; i++) {
auto p = create_proc();
set_parent_to_this(p);
pid[i] = start_proc(p, proc_test_1a, i);
}
for (int i = 0; i < 10; i++) {
int code, id;
id = wait(&code);
ASSERT(pid[code] == id);
printk("proc %d exit\n", code);
}
exit(0);
}

void proc_test()
{
printk("proc_test\n");
auto p = create_proc();
int pid = start_proc(p, proc_test_1, 0);
int t = 0;
while (1) {
int code;
int id = wait(&code);
if (id == -1)
break;
if (id == pid)
ASSERT(code == 0);
else
t |= 1 << (code - 20);
}
ASSERT(t == 1048575);
printk("proc_test PASS\n");
}