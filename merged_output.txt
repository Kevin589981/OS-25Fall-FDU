#sched.c

#include <kernel/sched.h>
#include <kernel/proc.h>
#include <kernel/mem.h>
#include <kernel/printk.h>
#include <aarch64/intrinsic.h>
#include <kernel/cpu.h>
#include <common/rbtree.h>
#include <kernel/debug.h>
#include <common/string.h>
#include <common/list.h>

extern bool panic_flag;
extern void swtch(KernelContext *new_ctx, KernelContext **old_ctx);
u64 proc_entry(void (*entry)(u64), u64 arg);
extern int idle_entry();
extern Proc idle_procs[];

#define PAGE_SIZE 4096
#define NICE_0_LOAD 1024

SpinLock global_sched_lock;

// 红黑树比较函数：按vruntime排序
static bool rb_proc_less(struct rb_node_ *lnode, struct rb_node_ *rnode)
{
    Proc *lproc = container_of(lnode, Proc, schinfo.node);
    Proc *rproc = container_of(rnode, Proc, schinfo.node);
    
    // vruntime小的在左边
    if (lproc->schinfo.vruntime < rproc->schinfo.vruntime)
        return true;
    if (lproc->schinfo.vruntime > rproc->schinfo.vruntime)
        return false;
    // vruntime相同时按pid排序，保证确定性
    return lproc->pid < rproc->pid;
}

void create_idle_proc()
{
    for (int i = 0; i < NCPU; i++) {
        cpus[i].sched.idle = &idle_procs[i];
        Proc *p = &idle_procs[i];
        p->state = RUNNING;
        p->idle = TRUE;
        p->pid = -1 - i;
        p->kstack = kalloc_page();
        p->parent = NULL;
        
        void *sp = (void *)p->kstack + PAGE_SIZE;
        p->kcontext = (KernelContext *)(sp - sizeof(KernelContext));
        p->kcontext->lr = (u64)proc_entry;
        p->kcontext->x0 = (u64)idle_entry;
        p->kcontext->x1 = (u64)0;
        cpus[i].sched.current_proc = p;
        cpus[i].sched.idle = p;
    }
}

void init_sched()
{
    create_idle_proc();
    
    init_spinlock(&global_sched_lock);
    
    for (int i = 0; i < NCPU; i++) {
        struct sched *s = &cpus[i].sched;
        init_spinlock(&s->lock);
        // 初始化红黑树
        s->run_queue.rb_node = NULL;
        s->task_count = 0;
        s->min_vruntime = 0;
        cpus[i].zombie_to_reap=kalloc(sizeof(KernelContext));
    }
}

Proc *thisproc()
{
    int id = cpuid();
    return cpus[id].sched.current_proc;
}

void init_schinfo(struct schinfo *p)
{
    p->vruntime = 0;
    p->nice = 0;
    p->start_exec_time = 0;
    p->node.rb_left = NULL;
    p->node.rb_right = NULL;
    p->node.__rb_parent_color = 0;
}

// void acquire_sched_lock()
// {
//     acquire_spinlock(&cpus[cpuid()].sched.lock);
// }

void release_sched_lock()
{
    release_spinlock(&cpus[cpuid()].sched.lock);
}

bool is_zombie(Proc *p)
{
    bool r;
    acquire_spinlock(&p->lock);
    // acquire_spinlock(&global_sched_lock);
    r = p->state == ZOMBIE;
    // release_spinlock(&global_sched_lock);
    release_spinlock(&p->lock);
    return r;
}

bool activate_proc(Proc *p)
{
    if (p->state == RUNNING || p->state == RUNNABLE) {
        return true;
    }
    
    if (p->state == SLEEPING || p->state == UNUSED) {
        // 选择任务数最少的CPU
        int target_cpu = 0;
        // u64 min_count = cpus[0].sched.task_count;
        
        // for (int i = 1; i < NCPU; i++) {
        //     if (cpus[i].sched.task_count < min_count) {
        //         min_count = cpus[i].sched.task_count;
        //         target_cpu = i;
        //     }
        // }
        for (int i=cpuid();i>=0;i=(i+1)%4)
        {
            target_cpu=i;
            if (!try_acquire_spinlock(&cpus[target_cpu].sched.lock)){
                continue;
            }
        
            // 新进程的vruntime设置为当前最小vruntime，避免饥饿
            p->schinfo.vruntime = cpus[target_cpu].sched.min_vruntime;
            p->state = RUNNABLE;
        
            // 插入红黑树
            _rb_insert(&p->schinfo.node, &cpus[target_cpu].sched.run_queue, rb_proc_less);
            cpus[target_cpu].sched.task_count++;
        
            release_spinlock(&cpus[target_cpu].sched.lock);
            return true;
        }
    }
    
    PANIC();
    return false;
}

// 更新当前进程的vruntime
static void update_vruntime(Proc *p, u64 current_time)
{
    if (p->idle) return;
    
    if (p->schinfo.start_exec_time == 0) {
        p->schinfo.start_exec_time = current_time;
        return;
    }
    
    u64 delta_exec = current_time - p->schinfo.start_exec_time;
    if (delta_exec > 0) {
        // vruntime增量 = 实际运行时间 * NICE_0_LOAD / weight
        int weight = WEIGHT(p->schinfo.nice);
        u64 delta_vruntime = (delta_exec * NICE_0_LOAD) / weight;
        p->schinfo.vruntime += delta_vruntime;
    }
    
    p->schinfo.start_exec_time = current_time;
}

static void update_this_state(enum procstate new_state)
{
    Proc *this = thisproc();
    if (this->idle) {
        return;
    }
    
    int my_cpu = cpuid();
    u64 current_time = get_timestamp(); // 需要实现获取时间戳的函数
    
    // 更新vruntime
    update_vruntime(this, current_time);
    
    // 更新min_vruntime
    if (this->schinfo.vruntime > cpus[my_cpu].sched.min_vruntime) {
        cpus[my_cpu].sched.min_vruntime = this->schinfo.vruntime;
    }
    
    this->state = new_state;
    
    if (new_state == RUNNABLE) {
        // RUNNING -> RUNNABLE: 插入红黑树
        _rb_insert(&this->schinfo.node, &cpus[my_cpu].sched.run_queue, rb_proc_less);
    } else if (new_state == SLEEPING || new_state == ZOMBIE||new_state==DYING) {
        // 从RUNNING变为SLEEPING/ZOMBIE，不需要操作红黑树（因为本来就不在树中）
        if (new_state == ZOMBIE||new_state==DYING) {
            cpus[my_cpu].sched.task_count--;
        }
    }
    // RUNNING状态的进程不在红黑树中
}

static Proc *pick_next()
{
    if (panic_flag) return cpus[cpuid()].sched.idle;
    
    int my_cpu = cpuid();
    struct rb_root_ *my_queue = &cpus[my_cpu].sched.run_queue;
    Proc *next_proc = NULL;
    
    // 从红黑树中选择最左节点（vruntime最小）
    struct rb_node_ *leftmost = _rb_first(my_queue);
    
    if (leftmost) {
        next_proc = container_of(leftmost, Proc, schinfo.node);
        _rb_erase(leftmost, my_queue);
        // cpus[my_cpu].sched.task_count--; // 注意：这里的task_count不应该减少，因为进程马上要被执行，它仍然是这个CPU的任务
        return next_proc;
    }
    
    // 当前队列为空，尝试工作窃取
    // 注意：此时持有 my_cpu 的锁
    
    Proc *stolen = NULL;
    for (int i = 0; i < NCPU; i++) {
        int target_cpu_id = (my_cpu + i + 1) % NCPU; // 从下一个CPU开始遍历，避免总从CPU0偷
        if (target_cpu_id == my_cpu) continue;
    
        // 尝试获取目标CPU的锁，如果获取不到就跳过，避免死锁和长时间等待
        if (!try_acquire_spinlock(&cpus[target_cpu_id].sched.lock)) {
            continue;
        }

        // ---- 在这里执行窃取逻辑 ----
        struct rb_root_ *other_queue = &cpus[target_cpu_id].sched.run_queue;
        if (cpus[target_cpu_id].sched.task_count > 0) {
            struct rb_node_ *leftmost_other = _rb_first(other_queue);
            if (leftmost_other) {
                stolen = container_of(leftmost_other, Proc, schinfo.node);
                _rb_erase(leftmost_other, other_queue);
                cpus[target_cpu_id].sched.task_count--;
            }
        }
        // ---------------------------
    
        release_spinlock(&cpus[target_cpu_id].sched.lock);
    
        // 如果窃取成功，就退出循环
        if (stolen) {
            break;
        }
    }
    
    // 如果窃取成功
    if (stolen) {
        // 调整vruntime以适应本地CPU的min_vruntime
        if (stolen->schinfo.vruntime < cpus[my_cpu].sched.min_vruntime) {
            stolen->schinfo.vruntime = cpus[my_cpu].sched.min_vruntime;
        }
        // 窃取来的任务现在属于我了
        cpus[my_cpu].sched.task_count++;
        return stolen;
    }
    
    // 如果循环结束都没有偷到，直接返回idle
    // 此时 my_cpu 的锁仍然被持有
    return cpus[my_cpu].sched.idle;
}

static void update_this_proc(Proc *p)
{
    cpus[cpuid()].sched.current_proc = p;
}

void sched(enum procstate new_state)
{
    auto this = thisproc();
    if (this->pid==1 && new_state==ZOMBIE){
        printk("init proc is dying\n");
    }
#ifdef debug_sched
    printk("this cpu is %lld, process's pid is %d, state is %d\n", 
           cpuid(), this->pid, this->state);
#endif
    ASSERT(this->state == RUNNING);
    
    update_this_state(new_state);
    // post_sem(&this->parent->childexit);
    auto next = pick_next();
    update_this_proc(next);
    
    if (next->state != RUNNABLE && !next->idle) {
        printk("This proc is: %d, it is %d\n", this->pid, this->state);
        printk("Next proc is: %d, it is %d\n", next->pid, next->state);
    }
    ASSERT(next->state == RUNNABLE || next->idle);
    
    next->state = RUNNING;
    next->schinfo.start_exec_time = get_timestamp();
    // if (new_state==DYING){
    //     cpus[cpuid()].zombie_to_reap=this;
    // }
    if (next != this) {
        *cpus[cpuid()].zombie_to_reap=*this->kcontext;
        auto old_ctx = &cpus[cpuid()].zombie_to_reap; //写到一个专门的无用页面上
        
        if (new_state!=ZOMBIE){
            old_ctx = &this->kcontext;
        }else {
            release_spinlock(&this->lock);
        }
        swtch(next->kcontext, old_ctx);
    }
    release_sched_lock();

    // if (cpus[cpuid()].zombie_to_reap){
    //     // acquire_spinlock(&global_sched_lock);
    //     Proc *p=cpus[cpuid()].zombie_to_reap;
    //     cpus[cpuid()].zombie_to_reap=NULL;
    //     p->state=ZOMBIE;
    //     post_sem(&p->parent->childexit);
    //     // release_spinlock(&global_sched_lock);
    // }

}

u64 proc_entry(void (*entry)(u64), u64 arg)
{
    release_sched_lock();
    set_return_addr(entry);
    return arg;
}


================================================================================
#proc.h

#pragma once

#include <common/defines.h>
#include <common/list.h>
#include <common/sem.h>
#include <common/rbtree.h>

enum procstate { UNUSED, RUNNABLE, RUNNING, SLEEPING, ZOMBIE,DYING };

typedef struct UserContext {
    u64 spsr, elr;
    u64 x[18];
} UserContext;

typedef struct KernelContext {
    u64 lr, x0, x1;
    u64 x[11];
} KernelContext;

// embeded data for procs
struct schinfo {
    u64 vruntime;
    struct rb_node_ node;  // 改为红黑树节点
    int nice;              // -20 到 19
    u64 start_exec_time;
};

extern int prio_to_weight[];
#define WEIGHT(priority) prio_to_weight[priority+20]
#define NICE_0_LOAD 1024

typedef struct Proc {
    bool killed;
    bool idle;
    int pid;
    int exitcode;
    enum procstate state;
    Semaphore childexit;
    ListNode children;
    ListNode ptnode;
    struct Proc *parent;
    struct schinfo schinfo;
    void *kstack;
    UserContext *ucontext;
    KernelContext *kcontext;
    SpinLock lock;
} Proc;

void init_kproc();
void init_proc(Proc *);
Proc *create_proc();
int start_proc(Proc *, void (*entry)(u64), u64 arg);
NO_RETURN void exit(int code);
int wait(int *exitcode);
================================================================================
#proc.c

#include <kernel/proc.h>
#include <kernel/mem.h>
#include <kernel/sched.h>
#include <aarch64/mmu.h>
#include <common/list.h>
#include <common/string.h>
#include <kernel/printk.h>
#include <kernel/debug.h>
#include <kernel/core.h>
#include <kernel/cpu.h>
#ifndef NCPU
#define NCPU 4
#endif
Proc root_proc;

void kernel_entry();
u64 proc_entry();

SpinLock global_process_lock;
int prio_to_weight[40]={
    /* -20 */     88761,     71755,     56483,     46273,     36291,
    /* -15 */     29154,     23254,     18705,     14949,     11916,
    /* -10 */      9548,      7620,      6100,      4904,      3906,
    /*  -5 */      3121,      2501,      1991,      1586,      1277,
    /*   0 */      1024,       820,       655,       526,       423,
    /*   5 */       335,       272,       215,       172,       137,
    /*  10 */       110,        87,        70,        56,        45,
    /*  15 */        36,        29,        23,        18,        15,
}; 
static int allocated_pid;

void init_pid_allocator(){
    allocated_pid=0;
}

int pid_allocator(){
    ++allocated_pid;
    return allocated_pid;
}

Proc idle_procs[NCPU];
// static u8 idle_stacks[NCPU][PAGE_SIZE] __attribute__((aligned(PAGE_SIZE)));


// typedef struct Proc {
//     bool killed;
//     bool idle;√
//     int pid;√
//     int exitcode;
//     enum procstate state;√
//     Semaphore childexit;
//     ListNode children;
//     ListNode ptnode;
//     struct Proc *parent;√
//     struct schinfo schinfo;
//     void *kstack;√
//     UserContext *ucontext;√
//     KernelContext *kcontext;√
// } Proc;


// init_kproc initializes the kernel process
// NOTE: should call after kinit
void init_kproc()
{
    // TODO:
    // 1. init global resources (e.g. locks, semaphores)
    init_spinlock(&global_process_lock);
    // pid计数器
    init_pid_allocator();
    
    // 2. init the root_proc (finished)

    init_proc(&root_proc);
    root_proc.parent = &root_proc;
    start_proc(&root_proc, kernel_entry, 123456);
}
// 在 init_proc 中初始化 schinfo
void init_proc(Proc *p)
{
    memset(p, 0, sizeof(Proc));

    acquire_spinlock(&global_process_lock);

    init_sem(&p->childexit, 1);
    init_list_node(&p->children);
    init_list_node(&p->ptnode);
    p->idle = FALSE;
    p->exitcode = 0;
    p->killed = FALSE;
    p->parent = NULL;
    p->pid = pid_allocator();
    p->state = UNUSED;
    p->kstack = kalloc_page();
    init_spinlock(&p->lock);
    // 初始化调度信息
    init_schinfo(&p->schinfo);
    
    if (p->kstack == NULL) {
        // release_spinlock(&global_process_lock);
        PANIC();
    }
    memset(p->kstack, 0, PAGE_SIZE);

    p->kcontext = (KernelContext *)((u64)p->kstack + PAGE_SIZE - 16 - sizeof(KernelContext));
    p->ucontext = (UserContext *)((u64)p->kstack + PAGE_SIZE - 16 - sizeof(KernelContext) - sizeof(UserContext));

    release_spinlock(&global_process_lock);
}

// wait 和 exit 函数保持不变

Proc *create_proc()
{
    Proc *p = kalloc(sizeof(Proc));
    if (p==NULL){
        PANIC();
    }
    init_proc(p);
    return p;
}

void set_parent_to_this(Proc *proc)
{
    // TODO: set the parent of proc to thisproc
    // NOTE: maybe you need to lock the process tree
    // NOTE: it's ensured that the old proc->parent = NULL
    
    acquire_spinlock(&global_process_lock);
    Proc *parent=thisproc();
    proc->parent=parent;
// #ifdef debug_page_fault
//     printk("proc.c:144: proc's ptnode is %llx\n", (u64)&proc->ptnode);
// #endif
    _insert_into_list(&parent->children,&proc->ptnode);
    release_spinlock(&global_process_lock);
}

int start_proc(Proc *p, void (*entry)(u64), u64 arg)
{
    // TODO:
    // 1. set the parent to root_proc if NULL
    if (p->parent==NULL){
        acquire_spinlock(&global_process_lock);
        p->parent=&root_proc;

        _insert_into_list(&root_proc.children, &p->ptnode);

        release_spinlock(&global_process_lock);
    }
    // 2. setup the kcontext to make the proc start with proc_entry(entry, arg)
    // void *sp=(void *)p->kstack+PAGE_SIZE;
    // sp-=sizeof(KernelContext);
    // p->kcontext=(KernelContext *)sp;
    // memset(p->kcontext,0,sizeof(KernelContext));
    p->kcontext->lr=(u64)proc_entry;
    p->kcontext->x0=(u64)entry;
    p->kcontext->x1=(u64)arg;
    // 3. activate the proc and return its pid
    p->state=UNUSED;
    int id =p->pid;
    activate_proc(p);//activate函数内部有锁
    // NOTE: be careful of concurrency
    printk("cpuid: %lld, start pid: %d, its parent is %d\n",cpuid(),p->pid,p->parent->pid);
    return id;

}

int wait(int *exitcode)
{
    // TODO:
    
    
    // 1. return -1 if no children
    // acquire_spinlock(&global_process_lock);
    // if (_empty_list(&parent->children)){
    //     release_spinlock(&global_process_lock);
    //     return -1;
    // }
    
    while (1){
        
        // if (_empty_list(&parent->children)){
        //     release_spinlock(&global_process_lock);
        //     return -1;
        // }
    // 2. wait for childexit
    // 3. if any child exits, clean it up and return its pid and exitcode
        Proc *parent=thisproc();
        acquire_spinlock(&global_process_lock);
        // printk("191:proc.c: wait(), parent pid is %d\n",parent->pid);
        bool has_children = !_empty_list(&parent->children);
        if (!has_children){
            // printk("194: proc.c: no children, parent pid is %d\n",parent->pid);
            release_spinlock(&global_process_lock);
            printk("194: proc.c: no children, parent pid is %d\n",parent->pid);
            return -1;
        }
        // printk("197:proc.c: wait(), parent pid is %d\n",parent->pid);
        Proc *zombie_child=NULL;
        // if (has_children) {
        _for_in_list(node, &parent->children) {
            if (node==&parent->children){
                continue;
            }
            Proc *p = container_of(node, Proc, ptnode);
            // printk("Checking child pid: %d\n", p->pid);
            if (is_zombie(p)) {
                zombie_child = p;
                printk("Found zombie child pid: %d\n", p->pid);
                break;
            }
            // if (node->next==&parent->children){
            //     break;
            // }
        }
        // printk("210:proc.c: wait(), parent pid is %d\n",parent->pid);
        // }
        if (zombie_child){
            if (exitcode!=NULL){
                *exitcode=zombie_child->exitcode;
            }
            int child_pid=zombie_child->pid;
            if (zombie_child->kstack){
                kfree_page(zombie_child->kstack);
            }
            _detach_from_list(&zombie_child->ptnode);
            // zombie_child->state=UNUSED;
            // zombie_child->pid=0;
            kfree(zombie_child);
            release_spinlock(&global_process_lock);
            return child_pid;
        }

    // NOTE: be careful of concurrency
        release_spinlock(&global_process_lock);
        wait_sem(&parent->childexit);

        
    }
}

NO_RETURN void exit(int code)
{
    // TODO:
    // 1. set the exitcode
    Proc *p=thisproc();
     
    acquire_spinlock(&global_process_lock);
    // acquire_sched_lock();
    // p->state=ZOMBIE; //会导致sched.c:163发生PANIC
#ifdef debug_sched //{ UNUSED, RUNNABLE, RUNNING, SLEEPING, ZOMBIE };
    printk("proc.c:224, p->state is %d\n",p->state);
#endif
    p->exitcode=code;
    // 2. clean up the resources
    
    // 3. transfer children to the root_proc, and notify the root_proc if there is zombie
    // _for_in_list(node,&p->children){
    //     Proc *child=container_of(node,Proc,ptnode);
    //     child->parent=&root_proc;
    // }

// #ifdef debug_page_fault
//     printk("proc's ptnode is %llx, proc's children is %llx\n", (u64)&p->ptnode,(u64)&p->children);
// #endif
    // if (!_empty_list(&p->children)){
    //     ListNode *temp=_detach_from_list(&p->children);
    //     _merge_list(&root_proc.children, temp);
    // }
    // bool has_zombie_to_reparent = false;

    // // 1. 遍历所有子进程，更新它们的 parent 指针并检查僵尸状态
    // //    使用 _for_in_list_safe 是一个好习惯，尽管在这里我们是移动整个列表
    // _for_in_list(node, &p->children) {
    //     Proc *child = container_of(node, Proc, ptnode);
        
    //     // 关键修复 #1: 更新父进程指针
    //     child->parent = &root_proc;

    //     // 关键修复 #2: 检查是否存在已是僵尸的子进程
    //     if (child->state == ZOMBIE) {
    //         has_zombie_to_reparent = true;
    //     }
    // }

    // // 2. 将整个子进程链表过继给 root_proc
    // if (!_empty_list(&p->children)) {
    //     // 你的 _merge_list 应该能正确地将 p->children 的所有节点
    //     // 移动到 root_proc.children 中。
    //     // 一个标准的实现是：
    //     // a. 取出 p->children 的第一个和最后一个节点
    //     // b. 将它们链接到 root_proc.children 的末尾
    //     ListNode *temp = _detach_from_list(&p->children);
    //     _merge_list(&root_proc.children, temp); // 假设你有这样的函数
    //                                                    // 如果你的_merge_list(dst, src_head)能工作，也可以
    // }
    
    // // 清空自己的子进程链表
    // init_list_node(&p->children);

    // if (has_zombie_to_reparent) {
    //     post_sem(&root_proc.childexit);
    // }

    ListNode orphaned_children;
    init_list_node(&orphaned_children);
    while (!_empty_list(&p->children)) {
        ListNode *child_node = p->children.next;
        _detach_from_list(child_node);
        _insert_into_list(&orphaned_children, child_node);
    }
    while (!_empty_list(&orphaned_children)) {
        ListNode *child_node = orphaned_children.next;
        _detach_from_list(child_node);
        _insert_into_list(&root_proc.children, child_node);
        Proc *child = container_of(child_node, Proc, ptnode);
        child->parent = &root_proc;
        if (is_zombie(child)) {
            if ((u64)&root_proc<0x20){
                printk("Error proc.c: 312\n");
            }
            post_sem(&root_proc.childexit);
        }

    }
    if (!p->parent){
        p->parent=&root_proc;
        _detach_from_list(&p->ptnode);
        _insert_into_list(&root_proc.children, &p->ptnode);
    }

    
    if ((u64)p->parent<0x20){
        printk("BUG at proc.c :325\n");
    }
    
    
    // 4. sched(ZOMBIE)
    
    // *cpus[cpuid()].zombie_to_reap=*p->kcontext;
    acquire_sched_lock();
    acquire_spinlock(&p->lock);


    post_sem(&p->parent->childexit);
    release_spinlock(&global_process_lock);
    // sched(DYING);
    sched(ZOMBIE);
    // NOTE: be careful of concurrency
    
    // kfree(p);
    PANIC(); // prevent the warning of 'no_return function returns'
}

================================================================================
#cpu.h

#pragma once

#include <kernel/proc.h>
#include <common/rbtree.h>
#include <common/list.h>

#define NCPU 4

struct sched {
    struct rb_root_ run_queue;  // 红黑树存储RUNNABLE进程
    SpinLock lock;
    u64 task_count;
    u64 min_vruntime;          // 跟踪最小vruntime
    struct Proc* current_proc; // 当前RUNNING进程
    struct Proc* idle;
};

struct cpu {
    bool online;
    struct rb_root_ timer;
    struct sched sched;
    KernelContext *zombie_to_reap; // 需要回收的僵尸进程
};

extern SpinLock global_sched_lock;
extern struct cpu cpus[NCPU];

void set_cpu_on();
void set_cpu_off();
================================================================================
#sem.c

#include <common/sem.h>
#include <kernel/mem.h>
#include <kernel/sched.h>
#include <kernel/printk.h>
#include <common/list.h>
#include <kernel/debug.h>
void init_sem(Semaphore *sem, int val)
{
    sem->val = val;
    init_spinlock(&sem->lock);
    init_list_node(&sem->sleeplist);
}

bool get_sem(Semaphore *sem)
{
    bool ret = false;
    acquire_spinlock(&sem->lock);
    if (sem->val > 0) {
        sem->val--;
        ret = true;
    }
    release_spinlock(&sem->lock);
    return ret;
}

int get_all_sem(Semaphore *sem)
{
    int ret = 0;
    acquire_spinlock(&sem->lock);
    if (sem->val > 0) {
        ret = sem->val;
        sem->val = 0;
    }
    release_spinlock(&sem->lock);
    return ret;
}

bool wait_sem(Semaphore *sem)
{
    acquire_spinlock(&sem->lock);
    if (--sem->val >= 0) {
        release_spinlock(&sem->lock);
        return true;
    }
    WaitData *wait = kalloc(sizeof(WaitData));
    wait->proc = thisproc();
    wait->up = false;

// #ifdef debug_sem
//     printk("sem->sleeplist: %llx",(u64)&sem->sleeplist);
// #endif
// #ifdef debug_page_fault
//     // printk("sem.c:54: proc's ptnode is %llx, ptnode.next is %llx, ptnode.prev is %llx\n", (u64)&p->ptnode, (u64)p->ptnode.next, (u64)p->ptnode.prev);
//     // printk("sem.c:55: proc's pid id %d\n",p->pid);
//     printk("sem->sleeplist: %llx\n",(u64)&sem->sleeplist);
//     // printk("[START_PROC] Before insert, root_proc.children is %llx, root_proc.children.next is %llx, root_proc.children.prev is %llx\n", (u64)&root_proc.children, (u64)root_proc.children.next, (u64)root_proc.children.prev);
// #endif
    _insert_into_list(&sem->sleeplist, &wait->slnode);
    acquire_sched_lock();
    release_spinlock(&sem->lock);
#ifdef debug_sched //{ UNUSED, RUNNABLE, RUNNING, SLEEPING, ZOMBIE };
    printk("proc.c:224, cpuid is %lld\n",cpuid());
#endif
    sched(SLEEPING);
    acquire_spinlock(&sem->lock); // also the lock for waitdata
    if (!wait->up) // wakeup by other sources
    {
        ASSERT(++sem->val <= 0);
        _detach_from_list(&wait->slnode);
    }
    release_spinlock(&sem->lock);
    bool ret = wait->up;
    kfree(wait);
    return ret;
}

void post_sem(Semaphore *sem)
{
    acquire_spinlock(&sem->lock);
    if (++sem->val <= 0) {
        ASSERT(!_empty_list(&sem->sleeplist));
        auto wait = container_of(sem->sleeplist.prev, WaitData, slnode);
        wait->up = true;
        _detach_from_list(&wait->slnode);
        activate_proc(wait->proc);
    }
    release_spinlock(&sem->lock);
}
================================================================================
#swtch.S

// Do kernel-mode context switch
// x0 (first parameter): new context ptr
// x1 (second parameter): addr to save old context ptr

#define pushp(a, b) stp a, b, [sp, #-0x10]!
#define popp(a, b) ldp a, b, [sp], #0x10 

.globl swtch
swtch:
// TODO: save and restore KernelContext
pushp(x28,x29)
pushp(x26,x27)
pushp(x24,x25)
pushp(x22,x23)
pushp(x20,x21)
pushp(x1,x19)
pushp(lr,x0)
mov x2,sp
str x2,[x1] //根据swtch函数，x1是旧进程的kcontext的指针
mov sp,x0 
popp(lr,x0)
popp(x1,x19)
popp(x20,x21)
popp(x22,x23)
popp(x24,x25)
popp(x26,x27)
popp(x28,x29)
ret

================================================================================
